{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries to build file by file and later convert to a DataFrame\n",
    "df_list = []\n",
    "folder = 'rt_html'\n",
    "for movie_html in os.listdir(folder):\n",
    "    with open(os.path.join(folder, movie_html)) as file:\n",
    "        soup = BeautifulSoup(file,'lxml')\n",
    "        soup_title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
    "        audience_title = int(soup.find('div', class_ ='audience-score meter').find('span').contents[0][:-1])\n",
    "        #num_score = soup.find('div', class_ ='audience-info hidden-xs superPageFontColor')\n",
    "        num_audience_ratings =int(soup.find('div',class_ = \"audience-info hidden-xs superPageFontColor\").contents[3].contents[2].strip().replace(',',''))\n",
    "        # Your code here\n",
    "        # Note: a correct implementation may take ~15 seconds to run\n",
    "        \n",
    "        \n",
    "        # Append to list of dictionaries\n",
    "        df_list.append({'title': soup_title,\n",
    "                        'audience_score': int(audience_title),\n",
    "                        'number_of_audience_ratings': int(num_audience_ratings)})\n",
    "df = pd.DataFrame(df_list, columns = ['title', 'audience_score', 'number_of_audience_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8fb3f",
   "metadata": {},
   "source": [
    "# Testing two Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c71147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run this code in udacity workspace or dowload the df_olution pkl file on your local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5269dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solution = pd.read_pickle('df_solution.pkl')\n",
    "df.sort_values('title', inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df_solution.sort_values('title', inplace = True)\n",
    "df_solution.reset_index(inplace = True, drop = True)\n",
    "pd.testing.assert_frame_equal(df, df_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ebb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5537fb9b",
   "metadata": {},
   "source": [
    "# Data Wrangling - p2 project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968fcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with we rate dog using twitter user @dogrates\n",
    "# the twitter archive  of the user @dog_rates, rates dog based on their humuorous  comment abt the dog\n",
    "# so we have the twitter archive downloaded as the dataset with content such as tweet id,timestamp, text for 5000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ecfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project step\n",
    "#1.Gathering >>Assessing >>Cleaning Data >> Storing Data >> Analyzing and visualization > and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a80049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages to import \n",
    "#1. pandas,Numpy , requests, tweepy, json\n",
    "# create written documents that contain images and export as pdf files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fe104",
   "metadata": {},
   "source": [
    "# Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4e2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing and creating interesting trustworthy analyses and visuals\n",
    "# work on Enhanced Twitter archive\n",
    "# a column contains each text tweet , so we can extract dog rating , dog name and dog stage(floppo, pupper, floofer) and , filtered tweet with ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bb6a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so basically , you will be needing to gathering some information through twitter API like retweet count, favorite count using the tweet id\n",
    "# querying twitter Api  to extract this info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba57a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every tweet has image assosciated with , we built a model that classify the breed of every image in every  tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620e9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2bc034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ofili\\Documents\\Projects\\Data Analysis\\Wrangle and Analyze Data\n",
      "c:\\Users\\ofili\\Documents\\Projects\\Data Analysis\\Wrangle and Analyze Data/data/\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "base = os.path.abspath(\"__file__\" + \"/../\")\n",
    "print(base)\n",
    "directory = base + '/data/'\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f162d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_collection = []\n",
    "with open(directory + '/tweet-json.txt') as fr:\n",
    "    A = fr.readlines()\n",
    "    for line in A:\n",
    "        first_man = json.loads(line)\n",
    "        #rint(first_man)\n",
    "        #rint(type(first_man))\n",
    "        list_collection.append(first_man)\n",
    "        \n",
    "df = pd.DataFrame(list_collection)\n",
    "    #for line in fr:\n",
    "     #   data = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e911ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['id','retweet_count','favorite_count',]]\n",
    "df1.columns = ['tweet_id','retweet_count','favorite_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf15250",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(directory + 'twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f85088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp',\n",
       "       'source', 'text', 'retweeted_status_id', 'retweeted_status_user_id',\n",
       "       'retweeted_status_timestamp', 'expanded_urls', 'rating_numerator',\n",
       "       'rating_denominator', 'name', 'doggo', 'floofer', 'pupper', 'puppo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ea35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet in tweet_df['tweet_id'].values:\n",
    "#    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f551c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_combinedf = tweet_df.merge(df1,how = 'inner', on ='tweet_id' )# to combine the two dataframes using tweet_id as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c759f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8853</td>\n",
       "      <td>39467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6514</td>\n",
       "      <td>33819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  retweet_count  \\\n",
       "0                  10  Phineas  None    None   None  None           8853   \n",
       "1                  10    Tilly  None    None   None  None           6514   \n",
       "\n",
       "   favorite_count  \n",
       "0           39467  \n",
       "1           33819  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_combinedf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8877295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# About the twitter developer's account\n",
    "#the twitter API requires an authoriser from user \n",
    "# so you need to import tweepy after installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbbd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d47196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth = tweepy.OAuth1UserHandler(consumer_key='',consumer_secret='',access_token='',access_token_secret='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc48decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api = tweepy.API(auth)# using the API method to access the RESTFUL API methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbabf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = df_1.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.errors.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbabbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is needed in next step:\n",
    "# carry out both visual assessments and programatic assessment\n",
    "# carry out al least 8 data quality issues, focus more on the missing values ,duplicate values, and some other stuffs\n",
    "#tidyness is based on structures,columns here , check for columns that are repetive, you might be required to melt some columns\n",
    "# in rowa\n",
    "# like carrying out the dog genres in the column using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a144a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf23e6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ofili\\Documents\\Projects\\Data Analysis\\Wrangle and Analyze Data\\18962_class_sunday.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ofili/Documents/Projects/Data%20Analysis/Wrangle%20and%20Analyze%20Data/18962_class_sunday.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(directory \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimage_predictions.tsv\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m wb:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ofili/Documents/Projects/Data%20Analysis/Wrangle%20and%20Analyze%20Data/18962_class_sunday.ipynb#ch0000012?line=1'>2</a>\u001b[0m     wb\u001b[39m.\u001b[39mwrite(r\u001b[39m.\u001b[39mcontent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "with open(directory + 'image-predictions.tsv','wb') as wb:\n",
    "    wb.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a589a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.read_csv(directory + 'image-predictions.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c512ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc5a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ab035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d219c28175c209f25980fd834e2967a612155df055214cd175588ce58b547988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
